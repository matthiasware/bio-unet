{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Input, merge, UpSampling2D, Cropping2D, ZeroPadding2D, Reshape, core, Convolution2D, Conv2DTranspose, Concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import preprocess\n",
    "from model_02 import get_model\n",
    "import pickle\n",
    "import splitdata\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "import losses\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding files in 'data/split'\n",
      "data/split/41_2_x.png \n",
      " data/split/41_2_y.png\n",
      "data/split/31_3_x.png \n",
      " data/split/31_3_y.png\n",
      "data/split/4_1_x.png \n",
      " data/split/4_1_y.png\n",
      "data/split/27_4_x.png \n",
      " data/split/27_4_y.png\n",
      "data/split/16_5_x.png \n",
      " data/split/16_5_y.png\n",
      "data/split/30_3_x.png \n",
      " data/split/30_3_y.png\n",
      "data/split/36_7_x.png \n",
      " data/split/36_7_y.png\n",
      "data/split/5_0_x.png \n",
      " data/split/5_0_y.png\n",
      "data/split/36_9_x.png \n",
      " data/split/36_9_y.png\n",
      "data/split/18_3_x.png \n",
      " data/split/18_3_y.png\n",
      "data/split/28_9_x.png \n",
      " data/split/28_9_y.png\n",
      "data/split/26_8_x.png \n",
      " data/split/26_8_y.png\n",
      "data/split/25_9_x.png \n",
      " data/split/25_9_y.png\n",
      "data/split/28_12_x.png \n",
      " data/split/28_12_y.png\n",
      "data/split/1_1_x.png \n",
      " data/split/1_1_y.png\n",
      "data/split/4_4_x.png \n",
      " data/split/4_4_y.png\n",
      "data/split/28_2_x.png \n",
      " data/split/28_2_y.png\n",
      "data/split/6_2_x.png \n",
      " data/split/6_2_y.png\n",
      "data/split/36_3_x.png \n",
      " data/split/36_3_y.png\n",
      "data/split/25_7_x.png \n",
      " data/split/25_7_y.png\n",
      "data/split/26_11_x.png \n",
      " data/split/26_11_y.png\n",
      "data/split/18_2_x.png \n",
      " data/split/18_2_y.png\n",
      "data/split/39_14_x.png \n",
      " data/split/39_14_y.png\n",
      "data/split/33_2_x.png \n",
      " data/split/33_2_y.png\n",
      "data/split/27_12_x.png \n",
      " data/split/27_12_y.png\n",
      "data/split/10_1_x.png \n",
      " data/split/10_1_y.png\n",
      "data/split/29_4_x.png \n",
      " data/split/29_4_y.png\n",
      "data/split/3_6_x.png \n",
      " data/split/3_6_y.png\n",
      "data/split/42_9_x.png \n",
      " data/split/42_9_y.png\n",
      "data/split/23_2_x.png \n",
      " data/split/23_2_y.png\n",
      "data/split/38_2_x.png \n",
      " data/split/38_2_y.png\n",
      "data/split/21_6_x.png \n",
      " data/split/21_6_y.png\n",
      "data/split/20_7_x.png \n",
      " data/split/20_7_y.png\n",
      "data/split/46_5_x.png \n",
      " data/split/46_5_y.png\n",
      "data/split/28_6_x.png \n",
      " data/split/28_6_y.png\n",
      "data/split/45_4_x.png \n",
      " data/split/45_4_y.png\n",
      "data/split/26_6_x.png \n",
      " data/split/26_6_y.png\n",
      "data/split/10_0_x.png \n",
      " data/split/10_0_y.png\n",
      "data/split/26_4_x.png \n",
      " data/split/26_4_y.png\n",
      "data/split/3_3_x.png \n",
      " data/split/3_3_y.png\n",
      "data/split/25_4_x.png \n",
      " data/split/25_4_y.png\n",
      "data/split/13_2_x.png \n",
      " data/split/13_2_y.png\n",
      "data/split/24_3_x.png \n",
      " data/split/24_3_y.png\n",
      "data/split/47_1_x.png \n",
      " data/split/47_1_y.png\n",
      "data/split/42_5_x.png \n",
      " data/split/42_5_y.png\n",
      "data/split/21_4_x.png \n",
      " data/split/21_4_y.png\n",
      "data/split/27_15_x.png \n",
      " data/split/27_15_y.png\n",
      "data/split/36_8_x.png \n",
      " data/split/36_8_y.png\n",
      "data/split/3_0_x.png \n",
      " data/split/3_0_y.png\n",
      "data/split/47_4_x.png \n",
      " data/split/47_4_y.png\n",
      "data/split/44_3_x.png \n",
      " data/split/44_3_y.png\n",
      "data/split/19_9_x.png \n",
      " data/split/19_9_y.png\n",
      "data/split/29_7_x.png \n",
      " data/split/29_7_y.png\n",
      "data/split/0_0_x.png \n",
      " data/split/0_0_y.png\n",
      "data/split/22_4_x.png \n",
      " data/split/22_4_y.png\n",
      "data/split/19_8_x.png \n",
      " data/split/19_8_y.png\n",
      "data/split/22_11_x.png \n",
      " data/split/22_11_y.png\n",
      "data/split/27_7_x.png \n",
      " data/split/27_7_y.png\n",
      "data/split/39_2_x.png \n",
      " data/split/39_2_y.png\n",
      "data/split/46_0_x.png \n",
      " data/split/46_0_y.png\n",
      "data/split/46_7_x.png \n",
      " data/split/46_7_y.png\n",
      "data/split/12_4_x.png \n",
      " data/split/12_4_y.png\n",
      "data/split/35_1_x.png \n",
      " data/split/35_1_y.png\n",
      "data/split/41_3_x.png \n",
      " data/split/41_3_y.png\n",
      "data/split/19_10_x.png \n",
      " data/split/19_10_y.png\n",
      "data/split/24_1_x.png \n",
      " data/split/24_1_y.png\n",
      "data/split/26_9_x.png \n",
      " data/split/26_9_y.png\n",
      "data/split/7_0_x.png \n",
      " data/split/7_0_y.png\n",
      "data/split/28_4_x.png \n",
      " data/split/28_4_y.png\n",
      "data/split/28_8_x.png \n",
      " data/split/28_8_y.png\n",
      "data/split/9_0_x.png \n",
      " data/split/9_0_y.png\n",
      "data/split/20_2_x.png \n",
      " data/split/20_2_y.png\n",
      "data/split/36_5_x.png \n",
      " data/split/36_5_y.png\n",
      "data/split/18_1_x.png \n",
      " data/split/18_1_y.png\n",
      "data/split/29_0_x.png \n",
      " data/split/29_0_y.png\n",
      "data/split/41_7_x.png \n",
      " data/split/41_7_y.png\n",
      "data/split/26_3_x.png \n",
      " data/split/26_3_y.png\n",
      "data/split/37_7_x.png \n",
      " data/split/37_7_y.png\n",
      "data/split/29_1_x.png \n",
      " data/split/29_1_y.png\n",
      "data/split/24_9_x.png \n",
      " data/split/24_9_y.png\n",
      "data/split/38_3_x.png \n",
      " data/split/38_3_y.png\n",
      "data/split/24_4_x.png \n",
      " data/split/24_4_y.png\n",
      "data/split/23_10_x.png \n",
      " data/split/23_10_y.png\n",
      "data/split/18_5_x.png \n",
      " data/split/18_5_y.png\n",
      "data/split/42_4_x.png \n",
      " data/split/42_4_y.png\n",
      "data/split/45_7_x.png \n",
      " data/split/45_7_y.png\n",
      "data/split/16_4_x.png \n",
      " data/split/16_4_y.png\n",
      "data/split/14_4_x.png \n",
      " data/split/14_4_y.png\n",
      "data/split/39_13_x.png \n",
      " data/split/39_13_y.png\n",
      "data/split/42_10_x.png \n",
      " data/split/42_10_y.png\n",
      "data/split/3_5_x.png \n",
      " data/split/3_5_y.png\n",
      "data/split/9_4_x.png \n",
      " data/split/9_4_y.png\n",
      "data/split/27_5_x.png \n",
      " data/split/27_5_y.png\n",
      "data/split/3_2_x.png \n",
      " data/split/3_2_y.png\n",
      "data/split/45_3_x.png \n",
      " data/split/45_3_y.png\n",
      "data/split/23_3_x.png \n",
      " data/split/23_3_y.png\n",
      "data/split/19_1_x.png \n",
      " data/split/19_1_y.png\n",
      "data/split/18_0_x.png \n",
      " data/split/18_0_y.png\n",
      "data/split/39_1_x.png \n",
      " data/split/39_1_y.png\n",
      "data/split/42_11_x.png \n",
      " data/split/42_11_y.png\n",
      "data/split/46_6_x.png \n",
      " data/split/46_6_y.png\n",
      "data/split/26_5_x.png \n",
      " data/split/26_5_y.png\n",
      "data/split/42_7_x.png \n",
      " data/split/42_7_y.png\n",
      "data/split/22_1_x.png \n",
      " data/split/22_1_y.png\n",
      "data/split/45_2_x.png \n",
      " data/split/45_2_y.png\n",
      "data/split/20_1_x.png \n",
      " data/split/20_1_y.png\n",
      "data/split/45_5_x.png \n",
      " data/split/45_5_y.png\n",
      "data/split/19_3_x.png \n",
      " data/split/19_3_y.png\n",
      "data/split/3_1_x.png \n",
      " data/split/3_1_y.png\n",
      "data/split/45_6_x.png \n",
      " data/split/45_6_y.png\n",
      "data/split/39_0_x.png \n",
      " data/split/39_0_y.png\n",
      "data/split/7_3_x.png \n",
      " data/split/7_3_y.png\n",
      "data/split/37_3_x.png \n",
      " data/split/37_3_y.png\n",
      "data/split/44_6_x.png \n",
      " data/split/44_6_y.png\n",
      "data/split/31_0_x.png \n",
      " data/split/31_0_y.png\n",
      "data/split/42_13_x.png \n",
      " data/split/42_13_y.png\n",
      "data/split/24_8_x.png \n",
      " data/split/24_8_y.png\n",
      "data/split/9_1_x.png \n",
      " data/split/9_1_y.png\n",
      "data/split/30_6_x.png \n",
      " data/split/30_6_y.png\n",
      "data/split/21_7_x.png \n",
      " data/split/21_7_y.png\n",
      "data/split/26_10_x.png \n",
      " data/split/26_10_y.png\n",
      "data/split/7_2_x.png \n",
      " data/split/7_2_y.png\n",
      "data/split/6_3_x.png \n",
      " data/split/6_3_y.png\n",
      "data/split/34_4_x.png \n",
      " data/split/34_4_y.png\n",
      "data/split/38_1_x.png \n",
      " data/split/38_1_y.png\n",
      "data/split/44_7_x.png \n",
      " data/split/44_7_y.png\n",
      "data/split/20_11_x.png \n",
      " data/split/20_11_y.png\n",
      "data/split/33_1_x.png \n",
      " data/split/33_1_y.png\n",
      "data/split/30_0_x.png \n",
      " data/split/30_0_y.png\n",
      "data/split/33_3_x.png \n",
      " data/split/33_3_y.png\n",
      "data/split/19_7_x.png \n",
      " data/split/19_7_y.png\n",
      "data/split/37_4_x.png \n",
      " data/split/37_4_y.png\n",
      "data/split/19_5_x.png \n",
      " data/split/19_5_y.png\n",
      "data/split/34_0_x.png \n",
      " data/split/34_0_y.png\n",
      "data/split/20_12_x.png \n",
      " data/split/20_12_y.png\n",
      "data/split/23_4_x.png \n",
      " data/split/23_4_y.png\n",
      "data/split/16_2_x.png \n",
      " data/split/16_2_y.png\n",
      "data/split/13_0_x.png \n",
      " data/split/13_0_y.png\n",
      "data/split/25_6_x.png \n",
      " data/split/25_6_y.png\n",
      "data/split/34_1_x.png \n",
      " data/split/34_1_y.png\n",
      "data/split/27_1_x.png \n",
      " data/split/27_1_y.png\n",
      "data/split/35_3_x.png \n",
      " data/split/35_3_y.png\n",
      "data/split/32_1_x.png \n",
      " data/split/32_1_y.png\n",
      "data/split/38_4_x.png \n",
      " data/split/38_4_y.png\n",
      "data/split/39_4_x.png \n",
      " data/split/39_4_y.png\n",
      "data/split/23_11_x.png \n",
      " data/split/23_11_y.png\n",
      "data/split/6_0_x.png \n",
      " data/split/6_0_y.png\n",
      "data/split/27_2_x.png \n",
      " data/split/27_2_y.png\n",
      "data/split/44_1_x.png \n",
      " data/split/44_1_y.png\n",
      "data/split/27_9_x.png \n",
      " data/split/27_9_y.png\n",
      "data/split/34_3_x.png \n",
      " data/split/34_3_y.png\n",
      "data/split/12_0_x.png \n",
      " data/split/12_0_y.png\n",
      "data/split/41_0_x.png \n",
      " data/split/41_0_y.png\n",
      "data/split/36_2_x.png \n",
      " data/split/36_2_y.png\n",
      "data/split/30_5_x.png \n",
      " data/split/30_5_y.png\n",
      "data/split/2_1_x.png \n",
      " data/split/2_1_y.png\n",
      "data/split/42_12_x.png \n",
      " data/split/42_12_y.png\n",
      "data/split/46_3_x.png \n",
      " data/split/46_3_y.png\n",
      "data/split/33_4_x.png \n",
      " data/split/33_4_y.png\n",
      "data/split/42_6_x.png \n",
      " data/split/42_6_y.png\n",
      "data/split/27_0_x.png \n",
      " data/split/27_0_y.png\n",
      "data/split/25_2_x.png \n",
      " data/split/25_2_y.png\n",
      "data/split/31_4_x.png \n",
      " data/split/31_4_y.png\n",
      "data/split/18_7_x.png \n",
      " data/split/18_7_y.png\n",
      "data/split/21_2_x.png \n",
      " data/split/21_2_y.png\n",
      "data/split/4_3_x.png \n",
      " data/split/4_3_y.png\n",
      "data/split/25_5_x.png \n",
      " data/split/25_5_y.png\n",
      "data/split/28_3_x.png \n",
      " data/split/28_3_y.png\n",
      "data/split/46_10_x.png \n",
      " data/split/46_10_y.png\n",
      "data/split/25_3_x.png \n",
      " data/split/25_3_y.png\n",
      "data/split/41_11_x.png \n",
      " data/split/41_11_y.png\n",
      "data/split/43_0_x.png \n",
      " data/split/43_0_y.png\n",
      "data/split/21_3_x.png \n",
      " data/split/21_3_y.png\n",
      "data/split/22_0_x.png \n",
      " data/split/22_0_y.png\n",
      "data/split/36_12_x.png \n",
      " data/split/36_12_y.png\n",
      "data/split/29_2_x.png \n",
      " data/split/29_2_y.png\n",
      "data/split/25_0_x.png \n",
      " data/split/25_0_y.png\n",
      "data/split/22_2_x.png \n",
      " data/split/22_2_y.png\n",
      "data/split/37_2_x.png \n",
      " data/split/37_2_y.png\n",
      "data/split/21_0_x.png \n",
      " data/split/21_0_y.png\n",
      "data/split/10_3_x.png \n",
      " data/split/10_3_y.png\n",
      "data/split/22_10_x.png \n",
      " data/split/22_10_y.png\n",
      "data/split/41_1_x.png \n",
      " data/split/41_1_y.png\n",
      "data/split/27_13_x.png \n",
      " data/split/27_13_y.png\n",
      "data/split/41_5_x.png \n",
      " data/split/41_5_y.png\n",
      "data/split/8_0_x.png \n",
      " data/split/8_0_y.png\n",
      "data/split/44_2_x.png \n",
      " data/split/44_2_y.png\n",
      "data/split/28_7_x.png \n",
      " data/split/28_7_y.png\n",
      "data/split/10_5_x.png \n",
      " data/split/10_5_y.png\n",
      "data/split/24_6_x.png \n",
      " data/split/24_6_y.png\n",
      "data/split/34_5_x.png \n",
      " data/split/34_5_y.png\n",
      "data/split/28_11_x.png \n",
      " data/split/28_11_y.png\n",
      "data/split/22_8_x.png \n",
      " data/split/22_8_y.png\n",
      "data/split/40_0_x.png \n",
      " data/split/40_0_y.png\n",
      "data/split/4_2_x.png \n",
      " data/split/4_2_y.png\n",
      "data/split/47_3_x.png \n",
      " data/split/47_3_y.png\n",
      "data/split/1_2_x.png \n",
      " data/split/1_2_y.png\n",
      "data/split/9_5_x.png \n",
      " data/split/9_5_y.png\n",
      "data/split/39_8_x.png \n",
      " data/split/39_8_y.png\n",
      "data/split/23_6_x.png \n",
      " data/split/23_6_y.png\n",
      "data/split/20_6_x.png \n",
      " data/split/20_6_y.png\n",
      "data/split/14_1_x.png \n",
      " data/split/14_1_y.png\n",
      "data/split/9_6_x.png \n",
      " data/split/9_6_y.png\n",
      "data/split/5_6_x.png \n",
      " data/split/5_6_y.png\n",
      "data/split/0_1_x.png \n",
      " data/split/0_1_y.png\n",
      "data/split/20_5_x.png \n",
      " data/split/20_5_y.png\n",
      "data/split/23_1_x.png \n",
      " data/split/23_1_y.png\n",
      "data/split/13_1_x.png \n",
      " data/split/13_1_y.png\n",
      "data/split/23_8_x.png \n",
      " data/split/23_8_y.png\n",
      "data/split/32_0_x.png \n",
      " data/split/32_0_y.png\n",
      "data/split/26_1_x.png \n",
      " data/split/26_1_y.png\n",
      "data/split/40_4_x.png \n",
      " data/split/40_4_y.png\n",
      "data/split/41_4_x.png \n",
      " data/split/41_4_y.png\n",
      "data/split/35_2_x.png \n",
      " data/split/35_2_y.png\n",
      "data/split/12_2_x.png \n",
      " data/split/12_2_y.png\n",
      "data/split/47_0_x.png \n",
      " data/split/47_0_y.png\n",
      "data/split/28_13_x.png \n",
      " data/split/28_13_y.png\n",
      "data/split/5_5_x.png \n",
      " data/split/5_5_y.png\n",
      "data/split/17_0_x.png \n",
      " data/split/17_0_y.png\n",
      "data/split/42_0_x.png \n",
      " data/split/42_0_y.png\n",
      "data/split/17_1_x.png \n",
      " data/split/17_1_y.png\n",
      "data/split/19_0_x.png \n",
      " data/split/19_0_y.png\n",
      "data/split/41_6_x.png \n",
      " data/split/41_6_y.png\n",
      "data/split/36_13_x.png \n",
      " data/split/36_13_y.png\n",
      "data/split/11_1_x.png \n",
      " data/split/11_1_y.png\n",
      "data/split/2_5_x.png \n",
      " data/split/2_5_y.png\n",
      "data/split/27_6_x.png \n",
      " data/split/27_6_y.png\n",
      "data/split/31_1_x.png \n",
      " data/split/31_1_y.png\n",
      "data/split/29_3_x.png \n",
      " data/split/29_3_y.png\n",
      "data/split/9_3_x.png \n",
      " data/split/9_3_y.png\n",
      "data/split/14_2_x.png \n",
      " data/split/14_2_y.png\n",
      "data/split/45_0_x.png \n",
      " data/split/45_0_y.png\n",
      "data/split/38_5_x.png \n",
      " data/split/38_5_y.png\n",
      "data/split/43_1_x.png \n",
      " data/split/43_1_y.png\n",
      "data/split/10_4_x.png \n",
      " data/split/10_4_y.png\n",
      "data/split/22_6_x.png \n",
      " data/split/22_6_y.png\n",
      "data/split/43_5_x.png \n",
      " data/split/43_5_y.png\n",
      "data/split/40_1_x.png \n",
      " data/split/40_1_y.png\n",
      "data/split/29_6_x.png \n",
      " data/split/29_6_y.png\n",
      "data/split/23_5_x.png \n",
      " data/split/23_5_y.png\n",
      "data/split/3_4_x.png \n",
      " data/split/3_4_y.png\n",
      "data/split/21_1_x.png \n",
      " data/split/21_1_y.png\n",
      "data/split/39_10_x.png \n",
      " data/split/39_10_y.png\n",
      "data/split/2_0_x.png \n",
      " data/split/2_0_y.png\n",
      "data/split/27_17_x.png \n",
      " data/split/27_17_y.png\n",
      "data/split/44_0_x.png \n",
      " data/split/44_0_y.png\n",
      "data/split/47_6_x.png \n",
      " data/split/47_6_y.png\n",
      "data/split/19_4_x.png \n",
      " data/split/19_4_y.png\n",
      "data/split/6_1_x.png \n",
      " data/split/6_1_y.png\n",
      "data/split/42_2_x.png \n",
      " data/split/42_2_y.png\n",
      "data/split/5_4_x.png \n",
      " data/split/5_4_y.png\n",
      "data/split/17_2_x.png \n",
      " data/split/17_2_y.png\n",
      "data/split/30_7_x.png \n",
      " data/split/30_7_y.png\n",
      "data/split/35_5_x.png \n",
      " data/split/35_5_y.png\n",
      "data/split/24_5_x.png \n",
      " data/split/24_5_y.png\n",
      "data/split/27_8_x.png \n",
      " data/split/27_8_y.png\n",
      "data/split/21_5_x.png \n",
      " data/split/21_5_y.png\n",
      "data/split/23_13_x.png \n",
      " data/split/23_13_y.png\n",
      "data/split/46_8_x.png \n",
      " data/split/46_8_y.png\n",
      "data/split/46_4_x.png \n",
      " data/split/46_4_y.png\n",
      "data/split/27_11_x.png \n",
      " data/split/27_11_y.png\n",
      "data/split/40_5_x.png \n",
      " data/split/40_5_y.png\n",
      "data/split/14_3_x.png \n",
      " data/split/14_3_y.png\n",
      "data/split/19_6_x.png \n",
      " data/split/19_6_y.png\n",
      "data/split/27_10_x.png \n",
      " data/split/27_10_y.png\n",
      "data/split/5_1_x.png \n",
      " data/split/5_1_y.png\n",
      "data/split/28_0_x.png \n",
      " data/split/28_0_y.png\n",
      "data/split/9_2_x.png \n",
      " data/split/9_2_y.png\n",
      "data/split/35_0_x.png \n",
      " data/split/35_0_y.png\n",
      "data/split/24_2_x.png \n",
      " data/split/24_2_y.png\n",
      "data/split/45_9_x.png \n",
      " data/split/45_9_y.png\n",
      "data/split/36_10_x.png \n",
      " data/split/36_10_y.png\n",
      "data/split/36_11_x.png \n",
      " data/split/36_11_y.png\n",
      "data/split/20_10_x.png \n",
      " data/split/20_10_y.png\n",
      "data/split/35_9_x.png \n",
      " data/split/35_9_y.png\n",
      "data/split/4_0_x.png \n",
      " data/split/4_0_y.png\n",
      "data/split/28_1_x.png \n",
      " data/split/28_1_y.png\n",
      "data/split/41_9_x.png \n",
      " data/split/41_9_y.png\n",
      "data/split/22_9_x.png \n",
      " data/split/22_9_y.png\n",
      "data/split/23_9_x.png \n",
      " data/split/23_9_y.png\n",
      "data/split/12_1_x.png \n",
      " data/split/12_1_y.png\n",
      "data/split/41_10_x.png \n",
      " data/split/41_10_y.png\n",
      "data/split/27_16_x.png \n",
      " data/split/27_16_y.png\n",
      "data/split/20_0_x.png \n",
      " data/split/20_0_y.png\n",
      "data/split/28_5_x.png \n",
      " data/split/28_5_y.png\n",
      "data/split/37_1_x.png \n",
      " data/split/37_1_y.png\n",
      "data/split/7_1_x.png \n",
      " data/split/7_1_y.png\n",
      "data/split/18_4_x.png \n",
      " data/split/18_4_y.png\n",
      "data/split/44_5_x.png \n",
      " data/split/44_5_y.png\n",
      "data/split/44_4_x.png \n",
      " data/split/44_4_y.png\n",
      "data/split/18_11_x.png \n",
      " data/split/18_11_y.png\n",
      "data/split/18_9_x.png \n",
      " data/split/18_9_y.png\n",
      "data/split/2_4_x.png \n",
      " data/split/2_4_y.png\n",
      "data/split/11_0_x.png \n",
      " data/split/11_0_y.png\n",
      "data/split/30_2_x.png \n",
      " data/split/30_2_y.png\n",
      "data/split/35_7_x.png \n",
      " data/split/35_7_y.png\n",
      "data/split/41_8_x.png \n",
      " data/split/41_8_y.png\n",
      "data/split/39_5_x.png \n",
      " data/split/39_5_y.png\n",
      "data/split/23_0_x.png \n",
      " data/split/23_0_y.png\n",
      "data/split/45_1_x.png \n",
      " data/split/45_1_y.png\n",
      "data/split/0_2_x.png \n",
      " data/split/0_2_y.png\n",
      "data/split/5_3_x.png \n",
      " data/split/5_3_y.png\n",
      "data/split/2_3_x.png \n",
      " data/split/2_3_y.png\n",
      "data/split/2_2_x.png \n",
      " data/split/2_2_y.png\n",
      "data/split/16_3_x.png \n",
      " data/split/16_3_y.png\n",
      "data/split/29_5_x.png \n",
      " data/split/29_5_y.png\n",
      "data/split/42_1_x.png \n",
      " data/split/42_1_y.png\n",
      "data/split/39_6_x.png \n",
      " data/split/39_6_y.png\n",
      "data/split/22_7_x.png \n",
      " data/split/22_7_y.png\n",
      "data/split/22_5_x.png \n",
      " data/split/22_5_y.png\n",
      "data/split/35_4_x.png \n",
      " data/split/35_4_y.png\n",
      "data/split/26_0_x.png \n",
      " data/split/26_0_y.png\n",
      "data/split/42_3_x.png \n",
      " data/split/42_3_y.png\n",
      "data/split/27_3_x.png \n",
      " data/split/27_3_y.png\n",
      "data/split/40_3_x.png \n",
      " data/split/40_3_y.png\n",
      "data/split/19_2_x.png \n",
      " data/split/19_2_y.png\n",
      "data/split/20_8_x.png \n",
      " data/split/20_8_y.png\n",
      "data/split/35_6_x.png \n",
      " data/split/35_6_y.png\n",
      "data/split/28_10_x.png \n",
      " data/split/28_10_y.png\n",
      "data/split/33_0_x.png \n",
      " data/split/33_0_y.png\n",
      "data/split/1_0_x.png \n",
      " data/split/1_0_y.png\n",
      "data/split/47_5_x.png \n",
      " data/split/47_5_y.png\n",
      "data/split/20_4_x.png \n",
      " data/split/20_4_y.png\n",
      "data/split/18_8_x.png \n",
      " data/split/18_8_y.png\n",
      "data/split/39_3_x.png \n",
      " data/split/39_3_y.png\n",
      "data/split/36_0_x.png \n",
      " data/split/36_0_y.png\n",
      "data/split/37_6_x.png \n",
      " data/split/37_6_y.png\n",
      "data/split/37_0_x.png \n",
      " data/split/37_0_y.png\n",
      "data/split/30_4_x.png \n",
      " data/split/30_4_y.png\n",
      "data/split/23_7_x.png \n",
      " data/split/23_7_y.png\n",
      "data/split/23_14_x.png \n",
      " data/split/23_14_y.png\n",
      "data/split/46_2_x.png \n",
      " data/split/46_2_y.png\n",
      "data/split/24_0_x.png \n",
      " data/split/24_0_y.png\n",
      "data/split/10_2_x.png \n",
      " data/split/10_2_y.png\n",
      "data/split/43_2_x.png \n",
      " data/split/43_2_y.png\n",
      "data/split/44_8_x.png \n",
      " data/split/44_8_y.png\n",
      "data/split/15_0_x.png \n",
      " data/split/15_0_y.png\n",
      "data/split/39_11_x.png \n",
      " data/split/39_11_y.png\n",
      "data/split/43_3_x.png \n",
      " data/split/43_3_y.png\n",
      "data/split/16_0_x.png \n",
      " data/split/16_0_y.png\n",
      "data/split/5_7_x.png \n",
      " data/split/5_7_y.png\n",
      "data/split/46_9_x.png \n",
      " data/split/46_9_y.png\n",
      "data/split/38_0_x.png \n",
      " data/split/38_0_y.png\n",
      "data/split/44_9_x.png \n",
      " data/split/44_9_y.png\n",
      "data/split/47_7_x.png \n",
      " data/split/47_7_y.png\n",
      "data/split/12_3_x.png \n",
      " data/split/12_3_y.png\n",
      "data/split/40_2_x.png \n",
      " data/split/40_2_y.png\n",
      "data/split/22_3_x.png \n",
      " data/split/22_3_y.png\n",
      "data/split/31_2_x.png \n",
      " data/split/31_2_y.png\n",
      "data/split/47_2_x.png \n",
      " data/split/47_2_y.png\n",
      "data/split/4_5_x.png \n",
      " data/split/4_5_y.png\n",
      "data/split/18_10_x.png \n",
      " data/split/18_10_y.png\n",
      "data/split/18_6_x.png \n",
      " data/split/18_6_y.png\n",
      "data/split/20_3_x.png \n",
      " data/split/20_3_y.png\n",
      "data/split/5_2_x.png \n",
      " data/split/5_2_y.png\n",
      "data/split/30_1_x.png \n",
      " data/split/30_1_y.png\n",
      "data/split/39_7_x.png \n",
      " data/split/39_7_y.png\n",
      "data/split/26_7_x.png \n",
      " data/split/26_7_y.png\n",
      "data/split/36_4_x.png \n",
      " data/split/36_4_y.png\n",
      "data/split/26_2_x.png \n",
      " data/split/26_2_y.png\n",
      "data/split/27_14_x.png \n",
      " data/split/27_14_y.png\n",
      "data/split/39_12_x.png \n",
      " data/split/39_12_y.png\n",
      "data/split/36_1_x.png \n",
      " data/split/36_1_y.png\n",
      "data/split/35_8_x.png \n",
      " data/split/35_8_y.png\n",
      "data/split/25_1_x.png \n",
      " data/split/25_1_y.png\n",
      "data/split/25_8_x.png \n",
      " data/split/25_8_y.png\n",
      "data/split/16_1_x.png \n",
      " data/split/16_1_y.png\n",
      "data/split/39_9_x.png \n",
      " data/split/39_9_y.png\n",
      "data/split/20_9_x.png \n",
      " data/split/20_9_y.png\n",
      "data/split/42_8_x.png \n",
      " data/split/42_8_y.png\n",
      "data/split/37_5_x.png \n",
      " data/split/37_5_y.png\n",
      "data/split/43_4_x.png \n",
      " data/split/43_4_y.png\n",
      "data/split/45_8_x.png \n",
      " data/split/45_8_y.png\n",
      "data/split/36_6_x.png \n",
      " data/split/36_6_y.png\n",
      "data/split/46_1_x.png \n",
      " data/split/46_1_y.png\n",
      "data/split/23_12_x.png \n",
      " data/split/23_12_y.png\n",
      "data/split/14_5_x.png \n",
      " data/split/14_5_y.png\n",
      "data/split/34_2_x.png \n",
      " data/split/34_2_y.png\n",
      "data/split/8_1_x.png \n",
      " data/split/8_1_y.png\n",
      "data/split/24_7_x.png \n",
      " data/split/24_7_y.png\n",
      "data/split/14_0_x.png \n",
      " data/split/14_0_y.png\n",
      "381\n"
     ]
    }
   ],
   "source": [
    "files = preprocess.get_split_files(\"data/split\")\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(files)\n",
    "files = files[0:]\n",
    "n_valid = int(np.ceil(len(files) * 0.15))\n",
    "n_test = int(np.ceil((len(files) - n_valid)* 0.15))\n",
    "n_train = len(files) - n_valid - n_test\n",
    "f_train = files[0:n_train]\n",
    "f_valid = files[n_train: n_train + n_valid]\n",
    "f_test = files[n_train + n_valid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274\n",
      "49\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "print(len(f_train))\n",
    "print(len(f_test))\n",
    "print(len(f_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "samples    274\n",
      "Img size  ( 512, 512)\n",
      "size      1.15 GB\n",
      "Loading data...\n",
      "samples     58\n",
      "Img size  ( 512, 512)\n",
      "size      0.24 GB\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = preprocess.load_split_data(f_train)\n",
    "X_valid, Y_valid = preprocess.load_split_data(f_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(274, 512, 512, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71827456\n",
      "210218.0\n",
      "0.0029267081379\n",
      "0.997073291862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_total = 274 * 512 * 512\n",
    "n_ones = np.sum(Y_train)\n",
    "print(n_total)\n",
    "print(n_ones)\n",
    "print(n_ones / n_total)\n",
    "print(1 - n_ones / n_total)\n",
    "0.0029 + 0.9971"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(274, 512, 512, 3)\n",
      "(274, 512, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1_1 (Conv2D)               (None, 512, 512, 1)  28          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv2D)               (None, 512, 512, 1)  10          conv_1_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool_1 (MaxPooling2D)           (None, 256, 256, 1)  0           conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 256, 256, 2)  20          pool_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_2 (Conv2D)                (None, 256, 256, 2)  38          conv2_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pool_2 (MaxPooling2D)           (None, 128, 128, 2)  0           conv2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_1 (Conv2D)               (None, 128, 128, 4)  76          pool_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_3_2 (Conv2D)               (None, 128, 128, 4)  148         conv_3_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool_3 (MaxPooling2D)           (None, 64, 64, 4)    0           conv_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_1 (Conv2D)               (None, 64, 64, 8)    296         pool_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_2 (Conv2D)               (None, 64, 64, 8)    584         conv_4_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool_4 (MaxPooling2D)           (None, 32, 32, 8)    0           conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_1 (Conv2D)               (None, 32, 32, 16)   1168        pool_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_2 (Conv2D)               (None, 32, 32, 16)   2320        conv_5_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 16)   2320        conv_5_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conc_5_4 (Concatenate)          (None, 64, 64, 24)   0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_6_1 (Conv2D)               (None, 64, 64, 8)    1736        conc_5_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_6_2 (Conv2D)               (None, 64, 64, 8)    584         conv_6_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 8)  584         conv_6_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conc_6_3 (Concatenate)          (None, 128, 128, 12) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv_3_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_7_1 (Conv2D)               (None, 128, 128, 4)  436         conc_6_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_7_2 (Conv2D)               (None, 128, 128, 4)  148         conv_7_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 4)  148         conv_7_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conc_7_2 (Concatenate)          (None, 256, 256, 6)  0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv_8_1 (Conv2D)               (None, 256, 256, 2)  110         conc_7_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_8_2 (Conv2D)               (None, 256, 256, 2)  38          conv_8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 512, 512, 2)  38          conv_8_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conc_8_1 (Concatenate)          (None, 512, 512, 3)  0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_9_1 (Conv2D)               (None, 512, 512, 1)  28          conc_8_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_9_2 (Conv2D)               (None, 512, 512, 1)  10          conv_9_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_10 (Conv2D)                (None, 512, 512, 1)  2           conv_9_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 10,870\n",
      "Trainable params: 10,870\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matthias/projects/bio-unet/model_02.py:87: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n",
      "  model = Model(input=inputs, output=conv10)\n"
     ]
    }
   ],
   "source": [
    "model = get_model(img_size=512, n_kernels=1)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.98, nesterov=True),\n",
    "              metrics=['accuracy'])\n",
    "#K.get_session().run(tf.global_variables_initializer())\n",
    "#tensorboard = TensorBoard(log_dir=\"logs\") \n",
    "callbacks = [\n",
    "             EarlyStopping(monitor='val_loss',\n",
    "                           patience=4,\n",
    "                           verbose=1),\n",
    "             ModelCheckpoint(\"model07.h5\",\n",
    "                             monitor='val_loss',\n",
    "                             save_best_only=True,\n",
    "                             verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`class_weight` not supported for 3+ dimensional targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cc27564360a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                  \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                  validation_data=(X_valid, Y_valid))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/intel-tf2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intel-tf2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    799\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                 zip(y, sample_weights, class_weights,\n\u001b[0;32m--> 801\u001b[0;31m                     feed_sample_weight_modes)\n\u001b[0m\u001b[1;32m    802\u001b[0m             ]\n\u001b[1;32m    803\u001b[0m             \u001b[0;31m# Check that all arrays have the same length.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intel-tf2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    797\u001b[0m             sample_weights = [\n\u001b[1;32m    798\u001b[0m                 \u001b[0mstandardize_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m                 zip(y, sample_weights, class_weights,\n\u001b[1;32m    801\u001b[0m                     feed_sample_weight_modes)\n",
      "\u001b[0;32m~/anaconda3/envs/intel-tf2/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_weights\u001b[0;34m(y, sample_weight, class_weight, sample_weight_mode)\u001b[0m\n\u001b[1;32m    498\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m             raise ValueError('`class_weight` not supported for '\n\u001b[0m\u001b[1;32m    501\u001b[0m                              '3+ dimensional targets.')\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `class_weight` not supported for 3+ dimensional targets."
     ]
    }
   ],
   "source": [
    "# batch_size determines the number of samples in each mini batch\n",
    "# steps_per_epoch the number of batch iterations before a training epoch is considered finished.\n",
    "# validation_steps\n",
    "hist = model.fit(x=X_train,\n",
    "                 y=Y_train,\n",
    "                 epochs=1,\n",
    "                 class_weight={1: 0.99, 0: 0.01},\n",
    "                 verbose=2, callbacks=callbacks,\n",
    "                 validation_data=(X_valid, Y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = hist.history['loss']\n",
    "test_loss = hist.history['val_loss']\n",
    "training_acc = hist.history['acc']\n",
    "test_acc = hist.history['val_acc']\n",
    "\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Validation Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();\n",
    "\n",
    "plt.plot(epoch_count, training_acc, 'r--')\n",
    "plt.plot(epoch_count, test_acc, 'b-')\n",
    "plt.legend(['Training Acc', 'Validation Acc'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model02.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, Y_test = load_split_data(f_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_pred = model.predict(X_test, batch_size=1, verbose=1)\n",
    "Y_round = np.around(Y_pred)\n",
    "\n",
    "for i in range(Y_pred.shape[0]):\n",
    "    preprocess.show_ndimg(X_test[i], Y_test[i])\n",
    "    preprocess.show_ndimg(Y_pred[i], Y_round[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "Y_pred = model.predict(X_train[0:n], batch_size=1, verbose=1)\n",
    "Y_round = np.around(Y_pred)\n",
    "\n",
    "for i in range(Y_pred.shape[0]):\n",
    "    preprocess.show_ndimg(X_train[i], Y_train[i])\n",
    "    preprocess.show_ndimg(Y_pred[i], Y_round[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_total = np.prod(Y_train[0].shape)\n",
    "n_ones = np.sum(Y_train[0])\n",
    "n_zeros = n_total - n_ones\n",
    "print(n_total)\n",
    "print(n_ones)\n",
    "print(n_zeros)\n",
    "w_zero = n_ones / n_total\n",
    "w_ones = n_zeros / n_total\n",
    "print(w_zero)\n",
    "print(w_ones)\n",
    "print(w_zero + w_ones)\n",
    "print(1 - 0.0022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(Y_pred.shape[0]):\n",
    "    preprocess.show_ndimg(X_test[i], Y_test[i])\n",
    "    preprocess.show_ndimg(Y_pred[i], Y_round[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
